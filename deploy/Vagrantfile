# -*- mode: ruby -*-
# vi: set ft=ruby :
require 'fileutils'
require './inventory'
# Please Make sure you run: vagrant plugin install vagrant-aws

skip_ansible = eval(ENV['skip_ansible']) ? ENV['skip_ansible'] : skip_ansible=false
DOMAIN = 'test.dev'.freeze
DEFAULT_PROVIDER = 'aws'.freeze
#KEY_PAIR_NAME = 'dev_key_pair'.freeze
KEY_PAIR_NAME=ENV['key_pair_name']
SSH_USERNAME = 'ec2-user'.freeze
inventory_groups = Inventory.new('./vagrant_hosts')
# profiles = Aws_Creds.new
# creds = profiles.get_creds('default')
SUBNET_ID='subnet-222db645'
DEFAULT_AMI='ami-011b3ccf1bd6db744'
Vagrant.configure(2) do |config|
    config.vm.box = 'centos/7'
    config.vbguest.auto_update = false
    # First make sure that an .vault_password file exists, and if it doesn't
    # then create an empty file
    FileUtils.touch('.vault_password') unless File.file?('.vault_password')

    # Constant var holding the root directory where this vagrantfile is being run
    VAGRANT_ROOT = File.dirname(File.expand_path(__FILE__))
    ansible_tags = ENV['TAGS']
    ansible_verbosity = ENV['V']

    ansible_extra_vars = if ENV['EXTRA_VARS']
                             eval(ENV['EXTRA_VARS'])
                         else
                             {}
                         end
    ansible_limit = ENV['LIMIT']

    x = inventory_groups.get_hosts_by_groups(nil)

    x.each do |_hosts_key, host_val|
        host_val.each do |host|
            hostname = host[:hostname]
            ipv4 = host[:ipv4]

            group_mapping = host[:group_mapping]
            root_storage = group_mapping['root_storage']
            additional_storage = group_mapping['additional_storage']
            ami=group_mapping['ami']? group_mapping['ami'] : ami=[DEFAULT_AMI,SSH_USERNAME]
            instance_type=group_mapping['instance_type']
            

            config.vm.define host[:hostname] do |mm_config|
                hypenated = "#{hostname}.#{DOMAIN}".tr('_', '-')
                mm_config.vm.hostname = hypenated
                mm_config.vm.network :private_network, ip: ipv4
                mm_config.ssh.forward_agent = true

                add_hard_drive(hostname, mm_config, group_mapping)

                mm_config.vm.box = 'aws_dummy'
                mm_config.vm.synced_folder '.', '/vagrant', disabled: true
                mm_config.vm.provider 'aws' do |aws, override|
                    aws.keypair_name = KEY_PAIR_NAME
                     
                    aws.instance_type =instance_type ? instance_type : aws.instance_type = nil
                    aws.ami = ami[0]  
                    override.ssh.username = ami[1] 
                 
                    
                    
                    override.ssh.private_key_path = "~/.ssh/#{KEY_PAIR_NAME}.pem"
                    aws.private_ip_address = ipv4
                    aws.subnet_id = SUBNET_ID
                    aws.tags = {
                        'Name' => 'aurora-'+hostname,
                        'Creator' => 'Hung',
                        'hostname' => hypenated
                    }
                end
                if skip_ansible==false then
                    mm_config.vm.provision 'ansible' do |ansible|
                        ansible.playbook = group_mapping['deploy_yaml']
                        ansible.inventory_path = 'vagrant_hosts'
                        ansible.tags = ansible_tags
                        ansible.verbose = ansible_verbosity
                        ansible.extra_vars = ansible_extra_vars
                        ansible.limit = ansible_limit
                    end
                end
            end
        end
    end
end

######################### Hellpers

def add_hard_drive(*params)
    hostname = params[0]
    config = params[1]
    group_mapping = params[2]
    root_storage = group_mapping['root_storage']
    additional_storage = group_mapping['additional_storage']
    root_storage = 10 if root_storage.nil?
    additional_storage = 0 if additional_storage.nil?
    config.vm.provider 'virtualbox' do |v|
        if  additional_storage > 0
            disk_file_1 = File.join(VAGRANT_ROOT, "gfs_brick_1_#{hostname}.vdi")

            # VBoxManage storagectl  to list controllers
            if File.exist?(disk_file_1)
                v.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', disk_file_1]
            else
                v.customize ['createhd', '--filename', disk_file_1, '--size', additional_storage, '--variant', 'fixed']
                v.customize ['storagectl', :id, '--name', 'SATA Controller', '--add', 'sata', '--portcount', 1]
                v.customize ['storageattach', :id, '--storagectl', 'SATA Controller', '--port', 1, '--device', 0, '--type', 'hdd', '--medium', disk_file_1]

            end
        end
    end
    config.vm.provider 'aws' do |aws|
        if additional_storage > 0
            aws.block_device_mapping = [{
                'DeviceName' => '/dev/sda1',
                'Ebs.VolumeSize' => root_storage,
                'Ebs.VolumeType' => 'gp2',
                'Ebs.DeleteOnTermination' => 'true'
            }, {
                'DeviceName' => '/dev/sda2',
                'Ebs.VolumeSize' => additional_storage,
                'Ebs.VolumeType' => 'gp2',
                'Ebs.DeleteOnTermination' => 'true'
            }]
        end
    end
end
